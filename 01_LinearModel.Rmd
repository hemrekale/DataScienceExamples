```{bash}
RETICULATE_MINICONDA_ENABLED=FALSE
```
```{python}
import os

```

<!-- http://r-statistics.co/Linear-Regression.html -->
  
Assumptions of linear regression:
    1- **Linearity**: The relationship between X and the mean of Y is linear.
    2 **Homoscedasticity**: The variance of residual is the same for any value of X.
    3- **Independence**: Observations are independent of each other.
Let's start with the built-in data set cars. cars data has 50 rows and two columns.

```{r}
setwd('/home/emre/fMRI/Codes_GH/DataScienceExamples')
#head(cars)
#str(cars)
#library(datarium) # The data database for R

```


## Load the data

In this section we will use the {\bf marketing} data set from the library datarium.
datarium is a R package for various data. You should install the package if you haven't yet.

```{r}
library(datarium)
head(marketing)
```
The data has four columns of which three of them are independent variables, and called youtube, facebook and newspaper. They are related to marketing expenditure. 

## Exploratory Data Analysis

### Scatter Plot
```{r}
#scatter.smooth(x=cars$speed, y=cars$dist, main="Dist ~ Speed",ylab = "Distance", xlab = "Speed")  # scatterplot
par(mfrow=c(1, 3)) 

scatter.smooth(x = marketing$youtube, y=marketing$sales, main="Sales ~ Youtube",xlab = "Youtube", ylab = "Sales")  # scatterplot
scatter.smooth(x = marketing$facebook, y=marketing$sales, main="Sales ~ Facebook",xlab = "Facebook", ylab = "")  # scatterplot
scatter.smooth(x = marketing$newspaper, y=marketing$sales, main="Sales ~ Newspaper",xlab = "Newspaper", ylab = "")  # scatterplot
#pairs(marketing)
```
Plot shows there is a linear (the first assumption) and increasing relationship between two variables. 

### Box plot
```{r}
par(mfrow=c(1, 3))  # divide graph area in 2 columns
boxplot(marketing$youtube, main="youtube")
boxplot(marketing$facebook, main="facebook")
boxplot(marketing$newspaper, main="newspaper")



#boxplot(marketing$sales)
#boxplot(cars$dist, main="Distance", sub=paste("Outlier value: ", boxplot.stats(cars$dist)$out))  # box plot for 'distance'
```

Newspaper columns has two outliers. Outliers can be detected usinq quantiles. 

IQR = 3rd Quantile - 1st Quantile

For a value of independent variable (x) 
if x > 3rd Quantile + 1.5*IQR or if x < 1st Quantile - 1.5*IQR then x is outlier.

Now we check if there is outliers in data. We will use builtin **IQR** and **quantile** functions to create our own FindOutliersIQR() function.
**quantile** fucntion returns a named vector, and in our example the  for the speed variable **quantile** function print and return:

```{r}
#summary(marketing[,-4])
```


The  **FindOutliersIQR()** function calculates inter-quantile range (IQR) using built-in IQR function and quantiles using the built-in quantile function. It uses these values to detect and return outliers if any. 

```{r}
FindOutliersIQR <- function(x) 
{
  x.quantile <- quantile(x) # cal
  x.IQR <- IQR(x)
  upper <- x.quantile["75%"]  + 1.5 * x.IQR
  lower <- x.quantile["25%"]  - 1.5 * x.IQR
  
  return(x[x < lower | x > upper])
}

outliers <- sapply(marketing[,-4], FindOutliersIQR)

print(outliers)
```

Only newspaper columns have outlier values (`r outliers$newspaper`) but we will ignore them right now.


```{r}
# youtube
par(mfrow = c(2,2))
hist(marketing$youtube,
 border="black",
 prob = TRUE, # show densities instead of frequencies
 xlab = "facebook",
 main = "Density and Histogram")
lines(density(marketing$youtube), # density plot
 lwd = 2, # thickness of line
 col = "blue")

# facebook
hist(marketing$facebook,
 border="black",
 prob = TRUE, # show densities instead of frequencies
 xlab = "facebook",
 main = "Density and Histogram")
lines(density(marketing$facebook), # density plot
 lwd = 2, # thickness of line
 col = "blue")

# newspaper
hist(marketing$newspaper,
 border="black",
 prob = TRUE, # show densities instead of frequencies
 xlab = "newspaper",
 main = "Density and Histogram")
lines(density(marketing$newspaper), # density plot
 lwd = 2, # thickness of line
 col = "blue")

# newspaper
hist(marketing$sales,
 border="black",
 prob = TRUE, # show densities instead of frequencies
 xlab = "sales",
 main = "Density and Histogram")
lines(density(marketing$sales), # density plot
 lwd = 2, # thickness of line
 col = "blue")




```

Note that none of the independent variables distributions look like normal but remember that using linear models it does not have to. The residuals of the linear model should be distributed normally. That we will check after we fit the model.


## Linear Models with Ordinary Least Squares
In this section, we will see how to built basic linear models using **lm()** and report results using **summary()** functions parameters and statistics of the model. We will start with the simplest model. The dependent varaible is dependent only on intercept.

### Only Intercept Model

First start with a simple model. Where Distance is modeled as a constant value $\beta_0$ that we want to estimate:

$$y = \beta_0 + \epsilon$$

As the first step we create a function that creates a line equation from estimated coefficients and intercept. 

```{r}
lm_eq <- function(model, yname = 'y' ) {
  
  a = format(unname(coef(model)[1]), digits = 3)
  b = format(unname(coef(model)[2]), digits = 3)
  r2 = format(summary(model)$r.squared, digits = 3)
  cc <-  coef(model)
  eqn <- paste(yname," = ", paste(round(cc[1],2), paste(round(cc[-1],2), names(cc[-1]), sep=" * ", collapse=" + "), sep=" + "), " e")
  return(eqn)
  #return(paste0(yname, ' = ',a, ' + ', b,'*', xname,'\n','R^2 = ',r2))
}
```

Next we create our model with only intercept plot the line on the scatter plot.

```{r}
marketing.simple <- lm(marketing$sales ~ 1)
with(marketing,(plot(x = youtube, y = sales, xlab = "youtube", ylab = "Sales")))
lines(marketing$youtube,fitted(marketing.simple), col = "blue")
text(x=40, y = 25, labels=lm_eq(marketing.simple))
```

```{r}
marketing.simple.summary <- summary(marketing.simple)

marketing.simple.summary
```

## Comparison of Only intercept term to one sample t-test. 

Using only intercept is the equivalent of hypotheses testing:

$H_0$ : true mean of speed is equal to zero

$H_1$ : true mean of speed is not equal to zero
  
This could be done with one-sample t-test:

```{r}
print(t.test(x = marketing$sales))
print(summary(marketing.simple) )
```

The p values (6.38e-16) are equal and estimated mean (42.980 ) is also same as it should be.

## Linear Model with only one dependent variable

The linear model for one exploratory variable is: 

$$y_i = \beta_{0i} + \beta_{1i}x$$
In our example:

$$Distance = \beta_0 + \beta_1 * Speed$$

To see, if we want to check if there is a linear relation between two variables, then we should check the slope of the model $\beta_1$ should be different then zero. So our hypothesis is:

$H_0 :\beta_1 =  0$

$H_1 :\beta_1 \neq 0$

First step is to fit the model and check the results by printing the model:

```{r}
cars.lm <- lm(dist ~ speed, data=cars)
print(cars.lm)
```

```{r}
marketing.lm.1 <- lm(sales ~ youtube , data=marketing)
summary.marketing.lm.1 <- summary(marketing.lm.1)

summary.marketing.lm.1$r.squared

#plot(marketing.lm.1)
```

When we check the coefficients of the model we see that our estimated fit is:
$$Sales =  `r format(coef(marketing.lm.1)[1],digits = 2)`  +  `r format(coef(marketing.lm.1)[2],digits = 2)` * Youtube$$

Similarly as we did on previous section, we can visualise the fit on the scatter plot.

```{r}
with(marketing,(plot(x = youtube, y = sales,xlab = "Youtube", ylab = "Sales")))
lines(marketing$youtube,fitted(marketing.lm.1))
text(x=70, y = 30, labels=lm_eq(marketing.lm.1))
```

which means one unit change in speed increase distance 3.932 units. Using summary function we can look at statistics.

```{r}


marketing.lm.1.summary <- summary(marketing.lm.1)
#marketing.lm.sd <- sqrt(deviance(marketing.lm.1) / df.residual(marketing.lm.1))

marketing.lm.1.coef <- marketing.lm.1.summary$coefficients 

marketing.lm.1.beta.estimate <- marketing.lm.1.coef["youtube", "Estimate"]  # get beta estimate for speed
marketing.lm.1.se <- marketing.lm.1.coef["youtube", "Std. Error"]  # get std.error for speed

t_value <- marketing.lm.1.summary$coefficients["youtube","t value"]
p_value <- marketing.lm.1.summary$coefficients["youtube","Pr(>|t|)"]

t_value <- marketing.lm.1.beta.estimate/marketing.lm.1.se  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(cars)-ncol(cars))  
```

Then t value of the coefficient estimate of the youtube effect is:

$t_{youtube}$ = `r format(t_value,digits = 4)`



```{r}
f <- marketing.lm.1.summary$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
print(model_p)
```
```{r}
marketing.lm.2 <- lm(sales ~ youtube + facebook , data=marketing)
summary.marketing.lm.2 <- summary(marketing.lm.2)
```

summary.marketing.lm.1$r.squared

\newcommand*\mean[1]{\bar{#1}}

# Model Evaluation

## $R^2$ and $R^2_{adjusted}$
When the model assumptions for linear model is met then either $R^2$ or $R^2_{adjusted}$ can be used to measure goodness-of-fit
Remember sum of squares (SSE) is: 
$$SSE = \sum_i{(y_i - \hat{y_i})^2}{}$$
where $y_i$ is each data and $\hat{y}_i$ is the model value. And total sum of squares (SST)  is :
$$SST = \sum_i{(y_i - {\mean{y_i}})^2}{}$$
SST is basically variance of the data and SSE is the variance of the residuals (unexplained). Then $R^2$ is the explained variance to total variance of the data. The closer the $R^2$ to 1 is better.
$$R^2 = 1 - \frac{SSE}{SST}$$
$R^2$ value can be obtained from the summary of the model : 
```{r}
marketing.lm.1.summary$r.squared
```

$R^2$ 


## Model fitting using linear algebra (optional)

Reference 1: http://r-statistics.co/Linear-Regression.html
  basic examples
Reference 2: From Faraday linear models with R
  linear algebra calculations
Reference 3: https://www.r-bloggers.com/2012/09/histogram-density-plot-combo-in-r/
  histograms
Reference 4: https://www.r-graph-gallery.com/44-polynomial-curve-fitting.html

Calculate $$X^tX$$ and then $$\beta = {(X^tX)}^{-1}X^ty$$:
# ```{r}
# X <- model.matrix ( ~ speed, data = cars)
# y <- cars$dist
# xtxi <- solve(t (X) %*% X)
# 
# beta <- solve (crossprod (X, X), crossprod (X, y))
# cars.residuals <- y - X %*% beta 
# 
# hist(cars.residuals, # histogram
#  border="black",
#  prob = TRUE, # show densities instead of frequencies
#  xlab = "Speed",
#  main = "Density and Histogram")
# lines(density(cars.residuals), # density plot
#  lwd = 2, # thickness of line
#  col = "blue")
# ```
```{r}
#sd <- sqrt(crossprod(cars.lm.summary$residuals,cars.lm.summary$residuals)/48)
```

## Solve using QR decomposition

QR decomposition is a more stable method to solve equation.

Buraya farawayden ve HARPtan cozumu koyalim.


## Sandwich Models and OLS

 http://www.sthda.com/english/articles/40-regression-analysis/167-simple-linear-regression-in-r/




